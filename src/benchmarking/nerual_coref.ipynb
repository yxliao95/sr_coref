{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_path = \"/root/workspace/fast-coref/coref_resources/reference-coreference-scorers/scorer.pl\"\n",
    "test_conll_path = \"/root/workspace/sr_coref/src/benchmarking/data/radcoref_test.conll\"\n",
    "output_file_path = \"/root/workspace/sr_coref/src/benchmarking/data/radcoref_pred_test.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_custom_conll(row):\n",
    "    obj = re.match(r\".+\\t\\d+\\t\\d+\\t(.*?)(\\t_){8}(\\t(.+))?\", row)\n",
    "    token_str = obj.group(1)\n",
    "    token_coref_ids = obj.group(4)\n",
    "    return token_str, token_coref_ids\n",
    "\n",
    "def extract_onto_conll(row):\n",
    "    str_list = re.split(r\" +\", row)\n",
    "    token_str = str_list[3]\n",
    "    token_coref_ids = str_list[-1] if str_list[-1] != \"-\" else None\n",
    "    return token_str, token_coref_ids\n",
    "\n",
    "row_info_extractor = extract_custom_conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load radcoref test conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(test_conll_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rows = f.readlines()\n",
    "    rows = [i.strip(\"\\n\") for i in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConllDocument:\n",
    "    def __init__(self, doc_key):\n",
    "        self.doc_key = doc_key\n",
    "        self.sent_toks = []\n",
    "        self.sent_tok_idx = []\n",
    "        self.gt_clusters = []  # [[start,end], ...]\n",
    "        self.pred_clusters = []\n",
    "\n",
    "        self._new_sent = True\n",
    "        self._tok_pointer = 0\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if self._new_sent:\n",
    "            self.sent_toks.append([])\n",
    "            self.sent_tok_idx.append([])\n",
    "            self._new_sent = False\n",
    "        self.sent_toks[-1].append(token)\n",
    "        self.sent_tok_idx[-1].append(self._tok_pointer)\n",
    "        self._tok_pointer += 1\n",
    "        return self._tok_pointer - 1\n",
    "    \n",
    "    def add_gt_cluster(self, token_coref_id, span_start, span_end):\n",
    "        while len(self.gt_clusters) < (token_coref_id + 1):\n",
    "            self.gt_clusters.append([])\n",
    "        if span_start is not None:\n",
    "            self.gt_clusters[token_coref_id].append([span_start, span_end])\n",
    "        elif span_start == None:\n",
    "            last_none_ele = next(filter(lambda x: x[1] is None, reversed(self.gt_clusters[token_coref_id])), None)\n",
    "            assert last_none_ele is not None\n",
    "            last_none_ele[1] = span_end\n",
    "        else:\n",
    "            raise RuntimeError(\"Should not see this.\")\n",
    "    \n",
    "    def add_pred_cluster(self, coref_id, span_start, span_end):\n",
    "        while len(self.pred_clusters) < (coref_id + 1):\n",
    "            self.pred_clusters.append([])\n",
    "        self.pred_clusters[coref_id].append([span_start, span_end])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.doc_key}: {self.gt_clusters}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_doc_obj = None\n",
    "doc_objs = []\n",
    "for row in rows:\n",
    "    if row == \"\" and current_doc_obj == None:\n",
    "        continue\n",
    "\n",
    "    if row.startswith(\"#begin\"):\n",
    "        obj = re.match(r\"#begin document \\((.+)\\); part 0\", row)\n",
    "        dockey = obj.group(1)\n",
    "        current_doc_obj = ConllDocument(dockey)\n",
    "    elif row == \"#end document\":\n",
    "        doc_objs.append(current_doc_obj)\n",
    "        current_doc_obj = None\n",
    "    else:\n",
    "        assert current_doc_obj != None\n",
    "        \n",
    "        # next sentence identifier\n",
    "        if row == \"\":\n",
    "            current_doc_obj._new_sent = True\n",
    "            continue\n",
    "\n",
    "        token_str, token_coref_ids= row_info_extractor(row)\n",
    "\n",
    "        # extracted token str\n",
    "        tok_idx = current_doc_obj.add_token(token_str)\n",
    "\n",
    "        # identify the coref cluster to which the token belongs\n",
    "        if token_coref_ids:\n",
    "            token_coref_id_list = token_coref_ids.split(\"|\")\n",
    "            for token_coref_id_str in token_coref_id_list:\n",
    "                token_coref_id = int(token_coref_id_str.strip(\"()\"))\n",
    "                span_start = tok_idx if token_coref_id_str.startswith(\"(\") else None\n",
    "                span_end = tok_idx if token_coref_id_str.endswith(\")\") else None\n",
    "                current_doc_obj.add_gt_cluster(token_coref_id, span_start, span_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using neural-coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f90eb1d76d8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[the right internal jugular vein catheter: [the right internal jugular vein catheter, its]]\n",
      "[a tracheostomy tube: [a tracheostomy tube, The tube]]\n",
      "[Small nodular opacity projecting over the right costo sternal junction: [Small nodular opacity projecting over the right costo sternal junction, It]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[a nasogastric tube: [a nasogastric tube, the tube]]\n",
      "[Dr. _ _ _: [Dr. _ _ _, Dr. _ _ _]]\n",
      "[the proximal right third rib: [the proximal right third rib, it]]\n",
      "[Left - sided PICC line: [Left - sided PICC line, its], Left - sided chest tube: [Left - sided chest tube, its], the left chest wall: [the left chest wall, the left chest wall], Dobbhoff and NG tubes: [Dobbhoff and NG tubes, their]]\n",
      "[the endotracheal tube 12 mm from the carina: [the endotracheal tube 12 mm from the carina, it]]\n",
      "[]\n",
      "[the carina: [the carina, it]]\n",
      "[rib fractures: [rib fractures, The fractures]]\n",
      "[Dr. _ _ _: [Dr. _ _ _, Dr. _ _ _]]\n",
      "[this: [this, it]]\n",
      "[Left subclavian PICC line: [Left subclavian PICC line, its]]\n",
      "[tube with the wire stylet in place: [tube with the wire stylet in place, the tube]]\n",
      "[]\n",
      "[]\n",
      "[Nasogastric tube: [Nasogastric tube, The tube]]\n",
      "[no definite pleural line: [no definite pleural line, It]]\n",
      "[the changes: [the changes, these changes], CT: [CT, CT, CT]]\n",
      "[These findings: [These findings, These findings]]\n",
      "[Right jugular line: [Right jugular line, Right PIC line]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[the endotracheal tube: [the endotracheal tube, The tube]]\n",
      "[]\n",
      "[This appearance: [This appearance, this appearance]]\n",
      "[the right lung: [the right lung, the right lung]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[This finding: [This finding, this finding, this finding]]\n",
      "[Right internal jugular central line: [Right internal jugular central line, its], Endotracheal tube: [Endotracheal tube, its]]\n",
      "[]\n",
      "[the patient: [the patient, The patient, its]]\n",
      "[The endotracheal tube position: [The endotracheal tube position, it]]\n",
      "[A right inferior pneumothorax: [A right inferior pneumothorax, It]]\n",
      "[the upper SVC: [the upper SVC, the upper SVC], the tip: [the tip, it]]\n",
      "[the prior radiograph of 1 day earlier: [the prior radiograph of 1 day earlier, the prior radiograph of 1 day earlier]]\n",
      "[tube: [tube, the tube]]\n",
      "[]\n",
      "[the left lung: [the left lung, the left lung]]\n",
      "[the nasogastric tube: [the nasogastric tube, its]]\n",
      "[the left PICC line: [the left PICC line, the line]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[the pulmonary vascularity: [the pulmonary vascularity, it]]\n",
      "[the basal pleural tube: [the basal pleural tube, ET tube]]\n",
      "[]\n",
      "[the findings: [the findings, the findings]]\n",
      "[the lung: [the lung, Left lung]]\n",
      "[chest CT: [chest CT, chest CT], CT: [CT, CT]]\n",
      "[Dr. _ _: [Dr. _ _, Dr. _ _]]\n",
      "[]\n",
      "[]\n",
      "[a chest CT: [a chest CT, the chest CT], CT: [CT, CT]]\n",
      "[]\n",
      "[]\n",
      "[Right subclavian PICC line: [Right subclavian PICC line, its]]\n",
      "[Endotracheal tube: [Endotracheal tube, it], the carina: [the carina, the carina]]\n",
      "[the right PICC line: [the right PICC line, the line, The line]]\n",
      "[]\n",
      "[]\n",
      "[THE PATIENT: [THE PATIENT, THE PATIENT, PATIENT]]\n",
      "[]\n",
      "[_ _ _: [_ _ _, _ _ _], the lung volumes: [the lung volumes, the lung volumes]]\n",
      "[CT: [CT, it, CT]]\n",
      "[possible concurrent pneumonia: [possible concurrent pneumonia, it]]\n",
      "[a short radiolucent segment of the tube outside the thoracic cavity: [a short radiolucent segment of the tube outside the thoracic cavity, This radiolucent segment]]\n",
      "[]\n",
      "[the patient: [the patient, The patient, the patient], the nasogastric tube: [the nasogastric tube, the tube]]\n",
      "[]\n",
      "[the SVC: [the SVC, the SVC]]\n",
      "[]\n",
      "[]\n",
      "[the ETT cuff: [the ETT cuff, it]]\n",
      "[]\n",
      "[]\n",
      "[this: [this, it, it]]\n",
      "[Endotracheal tube: [Endotracheal tube, its, The nasogastric tube], Left internal jugular central line: [Left internal jugular central line, its]]\n",
      "[Tracheostomy tube in place: [Tracheostomy tube in place, the tube]]\n",
      "[Chest CT scan: [Chest CT scan, The Chest CT scan], The right lung lesion: [The right lung lesion, The left apical lesion, it]]\n",
      "[Right lower lobe: [Right lower lobe, it]]\n",
      "[a Dobhoff tube with the opaque tip straddling the esophagogastric junction: [a Dobhoff tube with the opaque tip straddling the esophagogastric junction, The tube]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[the clavicles: [the clavicles, the clavicles], the distal stomach: [the distal stomach, the distal stomach], the mid stomach: [the mid stomach, the mid stomach]]\n",
      "[]\n",
      "[the current study: [the current study, the current study]]\n",
      "[A feeding tube: [A feeding tube, Endotracheal tube, its]]\n",
      "[]\n",
      "[the prior study: [the prior study, the prior study]]\n",
      "[]\n",
      "[]\n",
      "[A right IJ central venous catheter: [A right IJ central venous catheter, its]]\n",
      "[]\n",
      "[]\n",
      "[The multifocal bilateral airspace opacities: [The multifocal bilateral airspace opacities, they]]\n",
      "[]\n",
      "[the Port - A - Cath: [the Port - A - Cath, itself, it, its]]\n",
      "[Right PICC line: [Right PICC line, the line]]\n",
      "[the prior study: [the prior study, the prior study]]\n",
      "[a substantial improvement of the pre - existing cavitary lesion in the paraaortic lung regions: [a substantial improvement of the pre - existing cavitary lesion in the paraaortic lung regions, this improvement], The cavity: [The cavity, the cavity]]\n",
      "[the prior exam: [the prior exam, the prior exam], the pleural effusions: [the pleural effusions, the pleural effusions]]\n",
      "[The Dobbhoff tube: [The Dobbhoff tube, it], this film: [this film, the film, the film], the radiopaque segment seen on this exam is the Dobbhoff: [the radiopaque segment seen on this exam is the Dobbhoff, it]]\n",
      "[The changes: [The changes, The changes], the cardiac silhouette: [the cardiac silhouette, the cardiac silhouette]]\n",
      "[NG tube: [NG tube, its, The endotracheal tube, its]]\n",
      "[]\n",
      "[]\n",
      "[a new endotracheal tube with tip 3.2 cm above the level of the carina in appropriate position: [a new endotracheal tube with tip 3.2 cm above the level of the carina in appropriate position, NG tube, The NG tube], NG: [NG, NG]]\n",
      "[]\n",
      "[The lungs: [The lungs, The lungs]]\n",
      "[]\n",
      "[The tip: [The tip, It]]\n",
      "[a vague suggestion of some increased opacification at the left base: [a vague suggestion of some increased opacification at the left base, his], Two central catheters: [Two central catheters, They, They both]]\n",
      "[the endotracheal tube: [the endotracheal tube, its, The tube]]\n",
      "[the right lung: [the right lung, the right lung, the right lung], the minor fissure: [the minor fissure, it]]\n",
      "[]\n",
      "[]\n",
      "[AP: [AP, AP]]\n",
      "[patient: [patient, The patient], A right - sided PICC line: [A right - sided PICC line, its], Nasogastric tube: [Nasogastric tube, it]]\n",
      "[]\n",
      "[]\n",
      "[an endotracheal tube: [an endotracheal tube, The tube]]\n",
      "[]\n",
      "[]\n",
      "[the orogastric tube: [the orogastric tube, it, The ET tube], the tip: [the tip, the tip]]\n",
      "[AP: [AP, AP], A right - sided PICC line: [A right - sided PICC line, It, the line], _ _ _: [_ _ _, _ _ _]]\n",
      "[low lung volumes: [low lung volumes, The lung volumes]]\n",
      "[]\n",
      "[]\n",
      "[The lungs: [The lungs, The lungs]]\n",
      "[Endotracheal tube: [Endotracheal tube, its, The right chest tube, its, it]]\n",
      "[]\n",
      "[the left mid lung: [the left mid lung, the right lung, the right lung]]\n",
      "[pleural effusion: [pleural effusion, the effusion]]\n",
      "[No pleural effusions: [No pleural effusions, No pleural effusions]]\n",
      "[]\n",
      "[A CT: [A CT, that CT, the CT], CT: [CT, CT, CT]]\n",
      "[the patient: [the patient, The patient], The tube: [The tube, the tube, the tube]]\n",
      "[the basal pulmonary vasculature: [the basal pulmonary vasculature, The pulmonary vasculature]]\n",
      "[the patient: [the patient, The patient], a nasogastric tube: [a nasogastric tube, the tube, the tube], a new right internal jugular vein catheter: [a new right internal jugular vein catheter, the catheter]]\n",
      "[both bases: [both bases, the bases]]\n",
      "[The endotracheal tube: [The endotracheal tube, its]]\n",
      "[]\n",
      "[]\n",
      "[the right lung base: [the right lung base, the right lung base]]\n",
      "[the carina: [the carina, the carina]]\n",
      "[]\n",
      "[CT: [CT, CT]]\n",
      "[no pneumothorax: [no pneumothorax, no pneumothorax]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[the right lung: [the right lung, The left lung], the prior study: [the prior study, the prior study, the prior study]]\n",
      "[]\n",
      "[The endotracheal tube: [The endotracheal tube, The enteric tube]]\n",
      "[The lungs: [The lungs, They]]\n",
      "[An endotracheal tube: [An endotracheal tube, its], its tip: [its tip, the tip]]\n",
      "[the right base: [the right base, the left base]]\n",
      "[]\n",
      "[]\n",
      "[The pulmonary vasculature: [The pulmonary vasculature, the pulmonary vasculature]]\n",
      "[]\n",
      "[a nasogastric tube: [a nasogastric tube, the nasogastric tube], Dr. _ _ _: [Dr. _ _ _, Dr. _ _ _]]\n",
      "[the prior examination: [the prior examination, the prior examination]]\n",
      "[]\n",
      "[the chest: [the chest, the chest], The lungs: [The lungs, The lungs]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[prior PET - CT: [prior PET - CT, prior CT, prior CT, CT]]\n",
      "[]\n",
      "[The left - sided Port - A - Cath: [The left - sided Port - A - Cath, its]]\n",
      "[The lungs: [The lungs, the lungs]]\n",
      "[]\n",
      "[a new pleural effusion: [a new pleural effusion, this effusion]]\n",
      "[The IJ line: [The IJ line, The right - sided PICC line]]\n",
      "[the lateral view: [the lateral view, the frontal view], a 9 to 14 mm wide nodular opacity projecting over the retrosternal lung just superior to the pulmonary outflow tract: [a 9 to 14 mm wide nodular opacity projecting over the retrosternal lung just superior to the pulmonary outflow tract, the opacity]]\n",
      "[]\n",
      "[]\n",
      "[A right IJ pacer line: [A right IJ pacer line, its]]\n",
      "[]\n",
      "[]\n",
      "[The pre - existing left pleural effusion: [The pre - existing left pleural effusion, the effusion]]\n",
      "[Nasogastric tube: [Nasogastric tube, the tube], the lower esophagus: [the lower esophagus, the esophagus]]\n",
      "[AP: [AP, AP], The accessible pulmonary vasculature: [The accessible pulmonary vasculature, it]]\n",
      "[the left humeral head: [the left humeral head, The left humeral head]]\n",
      "[the tracheostomy tube: [the tracheostomy tube, the tracheostomy tube]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for doc_obj in doc_objs:\n",
    "    words = [tok for sent in doc_obj.sent_toks for tok in sent]\n",
    "    doc = Doc(nlp.vocab, words=words)\n",
    "    # 通过循环输出每个模块的处理结果\n",
    "    for pipe_name in nlp.pipe_names:\n",
    "        pipe = nlp.get_pipe(pipe_name)\n",
    "        doc = pipe(doc)\n",
    "    \n",
    "    # process the results\n",
    "    for cluster_id, cluster in enumerate(doc._.coref_clusters):\n",
    "        for mention in cluster.mentions:\n",
    "            start_idx = mention.start\n",
    "            end_idx = mention.end - 1\n",
    "            doc_obj.add_pred_cluster(cluster_id, start_idx, end_idx)\n",
    "\n",
    "    print(doc._.coref_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output pred conll file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConllToken(object):\n",
    "    def __init__(self, docId, sentenceId, tokenId, tokenStr):\n",
    "        self.docId = docId\n",
    "        self.sentenceId = sentenceId\n",
    "        self.tokenId = tokenId\n",
    "        self.tokenStr = tokenStr\n",
    "        self.corefLabel = \"\"\n",
    "\n",
    "    def add_coref_label(self, label, label_type):\n",
    "        if label_type == \"start\":\n",
    "            label = f\"({label}\"\n",
    "        elif label_type == \"end\":\n",
    "            label = f\"{label})\"\n",
    "        elif label_type == \"both\":\n",
    "            label = f\"({label})\"\n",
    "            \n",
    "        if not self.corefLabel:\n",
    "            self.corefLabel = label\n",
    "        else:\n",
    "            self.corefLabel = f\"{self.corefLabel}|{label}\"\n",
    "\n",
    "    def get_conll_str(self):\n",
    "        # IMPORTANT! Any tokens that trigger regex: \\((\\d+) or (\\d+)\\) will also\n",
    "        # trigger \"conll/reference-coreference-scorers\" unexpectedly,\n",
    "        # which will either cause execution error or wrong metric score.\n",
    "        # See coref/wrong_conll_scorer_example for details.\n",
    "        tok_str = self.tokenStr\n",
    "        if re.search(r\"\\(?[^A-Za-z]+\\)?\", tok_str):\n",
    "            tok_str = tok_str.replace(\"(\", \"[\").replace(\")\", \"]\")\n",
    "        if tok_str.strip() == \"\":\n",
    "            tok_str = \"\"\n",
    "        if self.corefLabel:\n",
    "            return f\"{self.docId}\\t0\\t{self.tokenId}\\t{tok_str}\\t\" + \"_\\t\" * 8 + self.corefLabel\n",
    "        return f\"{self.docId}\\t0\\t{self.tokenId}\\t{tok_str}\\t\" + \"_\\t\" * 7 + \"_\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.tokenStr}({self.sentenceId}:{self.tokenId})|[{self.corefLabel}]\"\n",
    "\n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_obj in doc_objs:\n",
    "    BEGIN = f\"#begin document ({doc_obj.doc_key}); part 0\\n\"\n",
    "    SENTENCE_SEPARATOR = \"\\n\"\n",
    "    END = \"#end document\\n\"\n",
    "    \n",
    "    sentence_list = []\n",
    "    for sent_id, sent in enumerate(doc_obj.sent_toks):\n",
    "        token_list = []\n",
    "        for tok_id, tok in enumerate(sent):\n",
    "            conll_token = ConllToken(docId=doc_obj.doc_key, \n",
    "                                    sentenceId=sent_id,\n",
    "                                    tokenId=tok_id, \n",
    "                                    tokenStr=tok)\n",
    "            token_list.append(conll_token)\n",
    "        sentence_list.append(token_list)\n",
    "        \n",
    "    conll_tokens = [c_tok for sent in sentence_list for c_tok in sent]\n",
    "    for coref_id, cluster in enumerate(doc_obj.pred_clusters):\n",
    "        for span in cluster:\n",
    "            start_idx = span[0]\n",
    "            end_idx = span[1]\n",
    "            if start_idx == end_idx:\n",
    "                conll_tokens[start_idx].add_coref_label(coref_id, label_type=\"both\")\n",
    "            else:\n",
    "                conll_tokens[start_idx].add_coref_label(coref_id, label_type=\"start\")\n",
    "                conll_tokens[end_idx].add_coref_label(coref_id, label_type=\"end\")\n",
    "    \n",
    "    with open(output_file_path, \"a\", encoding=\"UTF-8\") as out:\n",
    "        out.write(BEGIN)\n",
    "        for sent in sentence_list:\n",
    "            for tok in sent:\n",
    "                out.write(tok.get_conll_str() + \"\\n\")\n",
    "            out.write(SENTENCE_SEPARATOR)\n",
    "        out.write(END)\n",
    "        out.write(SENTENCE_SEPARATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_conll_script(\n",
    "    scorer_path: str, use_which_metric: str, groundtruth_file_path: str, predicted_file_path: str\n",
    "):\n",
    "    \"\"\"Args:\n",
    "        scorer_path: The path of the CoNLL scorer script: scorer.pl\n",
    "        use_which_metric: muc, bclub, ceafe\n",
    "        groundtruth_file_path: The path of the file serve as a ground truth file\n",
    "        predicted_file_path: The path of the file serve as a predicted output\n",
    "\n",
    "    Returns:\n",
    "        out: The standard output of the script.\n",
    "        err: The error message if the script is failed. Empty if no error.\n",
    "    \"\"\"\n",
    "    command = [scorer_path, use_which_metric, groundtruth_file_path, predicted_file_path, \"none\"]\n",
    "\n",
    "    result = subprocess.run(command, stdout=PIPE, stderr=PIPE)\n",
    "    out = result.stdout.decode(\"utf-8\")\n",
    "    err = result.stderr.decode(\"utf-8\")\n",
    "    if err:\n",
    "        err += f\" Error command: {command}\"\n",
    "    return out, err\n",
    "\n",
    "def resolve_conll_script_output(output_str):\n",
    "    \"\"\"Args:\n",
    "        output_str: The output of the CoNLL scorer script: scorer.pl. It only support single metric output, i.e. muc, bcub, ceafe, ceafm\n",
    "    Returns:\n",
    "        The percentage float value extracted from the script output. The ``%`` symble is omitted.\n",
    "    \"\"\"\n",
    "    regexPattern = r\"(\\d*\\.?\\d*)%\"\n",
    "    scores = [float(i) for i in re.findall(regexPattern, output_str)]\n",
    "    mention_recall = scores[0]\n",
    "    mention_precision = scores[1]\n",
    "    mention_f1 = scores[2]\n",
    "    coref_recall = scores[3]\n",
    "    coref_precision = scores[4]\n",
    "    coref_f1 = scores[5]\n",
    "    return mention_recall, mention_precision, mention_f1, coref_recall, coref_precision, coref_f1\n",
    "\n",
    "def compute_conll_score(conll_file_gt, conll_file_pred):\n",
    "    print(\"gt:\", conll_file_gt)\n",
    "    print(\"pred:\", conll_file_pred)\n",
    "    overall_f1 = []\n",
    "    for metric in ['muc', 'bcub', 'ceafe']:\n",
    "        out, err = invoke_conll_script(scorer_path, metric, conll_file_gt, conll_file_pred)\n",
    "        mention_recall, mention_precision, mention_f1, coref_recall, coref_precision, coref_f1 = resolve_conll_script_output(out)\n",
    "        overall_f1.append(coref_f1)\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"mention_recall, mention_precision, mention_f1: {mention_recall}, {mention_precision}, {mention_f1}\")\n",
    "        print(f\"coref_recall, coref_precision, coref_f1: {coref_recall}, {coref_precision}, {coref_f1}\")\n",
    "\n",
    "    print(f\"Overall F1: {sum(overall_f1) / len(overall_f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt: /root/workspace/sr_coref/src/benchmarking/data/radcoref_test.conll\n",
      "pred: /root/workspace/sr_coref/src/benchmarking/data/radcoref_pred_test.conll\n",
      "Metric: muc\n",
      "mention_recall, mention_precision, mention_f1: 44.03, 75.07, 55.5\n",
      "coref_recall, coref_precision, coref_f1: 38.62, 64.92, 48.43\n",
      "Metric: bcub\n",
      "mention_recall, mention_precision, mention_f1: 44.03, 75.07, 55.5\n",
      "coref_recall, coref_precision, coref_f1: 39.64, 67.24, 49.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: ceafe\n",
      "mention_recall, mention_precision, mention_f1: 44.03, 75.07, 55.5\n",
      "coref_recall, coref_precision, coref_f1: 41.03, 71.16, 52.05\n",
      "Overall F1: 50.120000000000005\n"
     ]
    }
   ],
   "source": [
    "compute_conll_score(conll_file_gt=test_conll_path, conll_file_pred=output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
